{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import io\n",
    "import random\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "from bert import data, model\n",
    "import pandas as pd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from scipy) (1.17.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.3'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)\n",
    "# change `ctx` to `mx.cpu()` if no GPU is available.\n",
    "#ctx = mx.gpu(0)\n",
    "ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/91/c85ddef872d5bb39949386930c1f834ac382e145fcd30155b09d6fb65c5a/sentence-transformers-0.2.5.tar.gz (49kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 851kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting transformers==2.3.0 (from sentence-transformers)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 1.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from sentence-transformers) (4.36.1)\n",
      "Requirement already satisfied: torch>=1.0.1 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from sentence-transformers) (1.4.0)\n",
      "Requirement already satisfied: numpy in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from sentence-transformers) (1.17.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from sentence-transformers) (0.21.3)\n",
      "Requirement already satisfied: scipy in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied: nltk in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from sentence-transformers) (3.4.5)\n",
      "Requirement already satisfied: requests in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from transformers==2.3.0->sentence-transformers) (2.22.0)\n",
      "Requirement already satisfied: boto3 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from transformers==2.3.0->sentence-transformers) (1.11.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from transformers==2.3.0->sentence-transformers) (2020.1.8)\n",
      "Requirement already satisfied: sacremoses in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from transformers==2.3.0->sentence-transformers) (0.0.38)\n",
      "Collecting sentencepiece (from transformers==2.3.0->sentence-transformers)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/56/2e6cfc364c4760b85adab40cb38d91e7ce67d6b2745a2e1aa1497c776fe1/sentencepiece-0.1.85-cp37-cp37m-macosx_10_6_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 2.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (0.13.2)\n",
      "Requirement already satisfied: six in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from requests->transformers==2.3.0->sentence-transformers) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from requests->transformers==2.3.0->sentence-transformers) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from requests->transformers==2.3.0->sentence-transformers) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from requests->transformers==2.3.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from boto3->transformers==2.3.0->sentence-transformers) (0.3.2)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.9 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from boto3->transformers==2.3.0->sentence-transformers) (1.14.9)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from boto3->transformers==2.3.0->sentence-transformers) (0.9.4)\n",
      "Requirement already satisfied: click in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers==2.3.0->sentence-transformers) (7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers==2.3.0->sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers==2.3.0->sentence-transformers) (0.15.2)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-0.2.5-cp37-none-any.whl size=64943 sha256=9fd8d6c3cc2ceab846e3e826dacca76f293b1d323d3a71116f2ba354bce90982\n",
      "  Stored in directory: /Users/rahul.b.sarkar/Library/Caches/pip/wheels/b4/ce/39/5bbda8ac34eb52df8c6531382ca077773fbfcbfb6386e5d66c\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, transformers, sentence-transformers\n",
      "Successfully installed sentence-transformers-0.2.5 sentencepiece-0.1.85 transformers-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mxnet-cu100\n",
    "!pip install bert-embedding --no-deps\n",
    "!pip install gluonnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mxnet-cu100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/0e/a91780d07592b1abf9c91344ce459472cc19db3b67fdf3a61dca6ebb2f5c/tensorflow_hub-0.7.0-py2.py3-none-any.whl (89kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 650kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_hub) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_hub) (1.17.2)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_hub) (3.11.2)\n",
      "Requirement already satisfied: setuptools in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.4.0->tensorflow_hub) (41.4.0)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.0.0-alpha\n",
      "  Using cached https://files.pythonhosted.org/packages/85/fb/6de0f86efab74e2f29fcc7372f12a59925276842f3c6ff6e032bd7a2bca9/tensorflow-2.0.0a0-cp37-cp37m-macosx_10_11_x86_64.whl\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-alpha) (1.12.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-alpha) (0.33.6)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-alpha) (1.17.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-alpha) (3.11.2)\n",
      "Requirement already satisfied: gast>=0.2.0 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-alpha) (0.2.2)\n",
      "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-alpha) (1.14.0a20190301)\n",
      "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-alpha) (1.14.0.dev2019030115)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-alpha) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-alpha) (1.0.8)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-alpha) (1.26.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-alpha) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-alpha) (0.9.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.2 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-alpha) (0.1.8)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.0.0-alpha) (0.8.1)\n",
      "Requirement already satisfied: setuptools in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==2.0.0-alpha) (41.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha) (0.16.0)\n",
      "Requirement already satisfied: h5py in /Users/rahul.b.sarkar/opt/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-alpha) (2.9.0)\n",
      "Installing collected packages: tensorflow\n",
      "  Found existing installation: tensorflow 1.13.2\n",
      "    Uninstalling tensorflow-1.13.2:\n",
      "      Successfully uninstalled tensorflow-1.13.2\n",
      "Successfully installed tensorflow-2.0.0a0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.0.0-alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-embedding\n",
      "  Downloading https://files.pythonhosted.org/packages/62/85/e0d56e29a055d8b3ba6da6e52afe404f209453057de95b90c01475c3ff75/bert_embedding-1.0.1-py3-none-any.whl\n",
      "Installing collected packages: bert-embedding\n",
      "Successfully installed bert-embedding-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bert-embedding --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTModel(\n",
      "  (encoder): BERTEncoder(\n",
      "    (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "    (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (1): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (2): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (3): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (4): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (5): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (6): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (7): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (8): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (9): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (10): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (11): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_embed): HybridSequential(\n",
      "    (0): Embedding(30522 -> 768, float32)\n",
      "    (1): Dropout(p = 0.1, axes=())\n",
      "  )\n",
      "  (token_type_embed): HybridSequential(\n",
      "    (0): Embedding(2 -> 768, float32)\n",
      "    (1): Dropout(p = 0.1, axes=())\n",
      "  )\n",
      "  (pooler): Dense(768 -> 768, Activation(tanh))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "bert_base, vocabulary = nlp.model.get_model('bert_12_768_12',\n",
    "                                             dataset_name='book_corpus_wiki_en_uncased',\n",
    "                                             pretrained=True, ctx=ctx, use_pooler=True,\n",
    "                                             use_decoder=False, use_classifier=False)\n",
    "print(bert_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classifier = model.classification.BERTClassifier(bert_base, num_classes=2, dropout=0.1)\n",
    "# only need to initialize the classifier layer.\n",
    "bert_classifier.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "bert_classifier.hybridize(static_alloc=True)\n",
    "\n",
    "# softmax cross entropy loss for classification\n",
    "loss_function = mx.gluon.loss.SoftmaxCELoss()\n",
    "loss_function.hybridize(static_alloc=True)\n",
    "\n",
    "metric = mx.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('aqsampledata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>RefAnswer</th>\n",
       "      <th>StudentAnswer</th>\n",
       "      <th>is_similar</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>Marks</th>\n",
       "      <th>Justification</th>\n",
       "      <th>Complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>A barcode is a series of light and dark bars o...</td>\n",
       "      <td>A barcode is a rectangular strip comprising of...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>tough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>With a code number printed underneath</td>\n",
       "      <td>A barcode is a rectangular strip comprising of...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Made up of country of origin code, manufacture...</td>\n",
       "      <td>A barcode is a rectangular strip comprising of...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>tough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A barcode is a rectangular strip comprising of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>tough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A barcode is a rectangular strip comprising of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          RefAnswer  \\\n",
       "0  0.0  A barcode is a series of light and dark bars o...   \n",
       "1  1.0              With a code number printed underneath   \n",
       "2  2.0  Made up of country of origin code, manufacture...   \n",
       "3  NaN                                                NaN   \n",
       "4  NaN                                                NaN   \n",
       "\n",
       "                                       StudentAnswer  is_similar  qid1  qid2  \\\n",
       "0  A barcode is a rectangular strip comprising of...         1.0   1.0   2.0   \n",
       "1  A barcode is a rectangular strip comprising of...         0.0   3.0   4.0   \n",
       "2  A barcode is a rectangular strip comprising of...         1.0   5.0   6.0   \n",
       "3  A barcode is a rectangular strip comprising of...         NaN   NaN   NaN   \n",
       "4  A barcode is a rectangular strip comprising of...         NaN   NaN   NaN   \n",
       "\n",
       "   Marks Justification Complexity  \n",
       "0      1             2      tough  \n",
       "1      0             0      tough  \n",
       "2      1             1      tough  \n",
       "3      1             1      tough  \n",
       "4      0             0       easy  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train_raw = train_df.RefAnswer + train_df.StudentAnswer\n",
    "#print(data_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\tRefAnswer\tStudentAnswer\tMarks\tJustification\tComplexity\n",
      "\n",
      "0\tA barcode is a series of light and dark bars of differing widths \tA barcode is a rectangular strip comprising of light and deep colors with a code number printed used for product identification and selling.\t1\t2\ttough\n",
      "\n",
      "1\tWith a code number printed underneath\tA barcode is a bar with product code printed. It is attached to every product at retail shops.\t0\t0\ttough\n",
      "\n",
      "2\tMade up of country of origin code, manufacturer code, the product code, a check digit.\tIt is a machine readable numbers arranged in a sequence comprising of parallel lines of different widths on a package. This is used for electronic scanning of goods at checkout to register price.\t1\t1\ttough\n",
      "\n",
      "3\t\tBarcode is a unique series of parallel lines printed on a product. It is used to register check out price and stock management.\t1\t1\ttough\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsv_file = io.open('train.tsv', encoding='utf-8')\n",
    "for i in range(5):\n",
    "    print(tsv_file.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_discard_samples = 1\n",
    "# Split fields by tabs\n",
    "field_separator = nlp.data.Splitter('\\t')\n",
    "# Fields to select from the file\n",
    "field_indices = [0, 1, 2]\n",
    "data_train_raw = nlp.data.TSVDataset(filename='train.tsv',\n",
    "                                 field_separator=field_separator,\n",
    "                                 num_discard_samples=num_discard_samples,\n",
    "                                 field_indices=field_indices)\n",
    "sample_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gluonnlp.data.dataset.TSVDataset object at 0x1b976f310>\n"
     ]
    }
   ],
   "source": [
    "print(data_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "A barcode is a series of light and dark bars of differing widths \n",
      "A barcode is a rectangular strip comprising of light and deep colors with a code number printed used for product identification and selling.\n"
     ]
    }
   ],
   "source": [
    "# Sentence A\n",
    "print(data_train_raw[sample_id][0])\n",
    "# Sentence B\n",
    "print(data_train_raw[sample_id][1])\n",
    "# 1 means equivalent, 0 means not equivalent\n",
    "print(data_train_raw[sample_id][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'A barcode is a rectangular strip comprising of light and deep colors with a code number printed used for product identification and selling.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-aa41e22838fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s token id = %s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s token id = %s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'token ids = \\n%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid length = \\n%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'segment ids = \\n%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/mxnet/gluon/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Workspace/AQAVisit/sentence_embedding/bert/data/transform.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# map to int if class labels are available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'A barcode is a rectangular strip comprising of light and deep colors with a code number printed used for product identification and selling.'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use the vocabulary from pre-trained model for tokenization\n",
    "bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "\n",
    "# The maximum length of an input sequence\n",
    "max_len = 128\n",
    "\n",
    "# The labels for the two classes [(0 = not similar) or  (1 = medium marks) or 2 = correct marks]\n",
    "all_labels = [\"0\"]\n",
    "\n",
    "# whether to transform the data as sentence pairs.\n",
    "# for single sentence classification, set pair=False\n",
    "# for regression task, set class_labels=None\n",
    "# for inference without label available, set has_label=False\n",
    "pair = True\n",
    "transform = data.transform.BERTDatasetTransform(bert_tokenizer, max_len,\n",
    "                                                class_labels=all_labels,\n",
    "                                                has_label=True,\n",
    "                                                pad=True,\n",
    "                                                pair=pair)\n",
    "data_train = data_train_raw.transform(transform)\n",
    "\n",
    "print('vocabulary used for tokenization = \\n%s'%vocabulary)\n",
    "print('%s token id = %s'%(vocabulary.padding_token, vocabulary[vocabulary.padding_token]))\n",
    "print('%s token id = %s'%(vocabulary.cls_token, vocabulary[vocabulary.cls_token]))\n",
    "print('%s token id = %s'%(vocabulary.sep_token, vocabulary[vocabulary.sep_token]))\n",
    "print('token ids = \\n%s'%data_train[sample_id][0])\n",
    "print('valid length = \\n%s'%data_train[sample_id][1])\n",
    "print('segment ids = \\n%s'%data_train[sample_id][2])\n",
    "print('label = \\n%s'%data_train[sample_id][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'A barcode is a rectangular strip comprising of light and deep colors with a code number printed used for product identification and selling.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-1bd189f2fa5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s token id = %s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s token id = %s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'token ids = \\n%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid length = \\n%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'segment ids = \\n%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/mxnet/gluon/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Workspace/AQAVisit/sentence_embedding/bert/data/transform.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# map to int if class labels are available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'A barcode is a rectangular strip comprising of light and deep colors with a code number printed used for product identification and selling.'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use the vocabulary from pre-trained model for tokenization\n",
    "bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "\n",
    "# The maximum length of an input sequence\n",
    "max_len = 128\n",
    "\n",
    "# The labels for the two classes [(0 = not similar) or  (1 = medium marks) or 2 = correct marks]\n",
    "all_labels = [\"0\", \"1\", \"2\", \"3\"]\n",
    "\n",
    "# whether to transform the data as sentence pairs.\n",
    "# for single sentence classification, set pair=False\n",
    "# for regression task, set class_labels=None\n",
    "# for inference without label available, set has_label=False\n",
    "pair = True\n",
    "transform = data.transform.BERTDatasetTransform(bert_tokenizer, max_len,\n",
    "                                                class_labels=all_labels,\n",
    "                                                has_label=True,\n",
    "                                                pad=True,\n",
    "                                                pair=pair)\n",
    "data_train = data_train_raw.transform(transform)\n",
    "\n",
    "print('vocabulary used for tokenization = \\n%s'%vocabulary)\n",
    "print('%s token id = %s'%(vocabulary.padding_token, vocabulary[vocabulary.padding_token]))\n",
    "print('%s token id = %s'%(vocabulary.cls_token, vocabulary[vocabulary.cls_token]))\n",
    "print('%s token id = %s'%(vocabulary.sep_token, vocabulary[vocabulary.sep_token]))\n",
    "print('token ids = \\n%s'%data_train[sample_id][0])\n",
    "print('valid length = \\n%s'%data_train[sample_id][1])\n",
    "print('segment ids = \\n%s'%data_train[sample_id][2])\n",
    "print('label = \\n%s'%data_train[sample_id][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 4/6] loss=0.6419, lr=0.0000050, acc=0.492\n",
      "[Epoch 1 Batch 4/6] loss=0.7024, lr=0.0000050, acc=0.375\n",
      "[Epoch 2 Batch 4/6] loss=0.7097, lr=0.0000050, acc=0.594\n"
     ]
    }
   ],
   "source": [
    "# The hyperparameters\n",
    "batch_size = 32\n",
    "lr = 5e-6\n",
    "\n",
    "# The FixedBucketSampler and the DataLoader for making the mini-batches\n",
    "train_sampler = nlp.data.FixedBucketSampler(lengths=[int(item[1]) for item in data_train],\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "bert_dataloader = mx.gluon.data.DataLoader(data_train, batch_sampler=train_sampler)\n",
    "\n",
    "trainer = mx.gluon.Trainer(bert_classifier.collect_params(), 'adam',\n",
    "                           {'learning_rate': lr, 'epsilon': 1e-9})\n",
    "\n",
    "# Collect all differentiable parameters\n",
    "# `grad_req == 'null'` indicates no gradients are calculated (e.g. constant parameters)\n",
    "# The gradients for these params are clipped later\n",
    "params = [p for p in bert_classifier.collect_params().values() if p.grad_req != 'null']\n",
    "grad_clip = 1\n",
    "\n",
    "# Training the model with only three epochs\n",
    "log_interval = 4\n",
    "num_epochs = 3\n",
    "for epoch_id in range(num_epochs):\n",
    "    metric.reset()\n",
    "    step_loss = 0\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(bert_dataloader):\n",
    "        with mx.autograd.record():\n",
    "\n",
    "            # Load the data to the GPU\n",
    "            token_ids = token_ids.as_in_context(ctx)\n",
    "            valid_length = valid_length.as_in_context(ctx)\n",
    "            segment_ids = segment_ids.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "\n",
    "            # Forward computation\n",
    "            out = bert_classifier(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "            ls = loss_function(out, label).mean()\n",
    "\n",
    "        # And backwards computation\n",
    "        ls.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        trainer.allreduce_grads()\n",
    "        nlp.utils.clip_grad_global_norm(params, 1)\n",
    "        trainer.update(1)\n",
    "\n",
    "        step_loss += ls.asscalar()\n",
    "        metric.update([label], [out])\n",
    "\n",
    "        # Printing vital information\n",
    "        if (batch_id + 1) % (log_interval) == 0:\n",
    "            print('[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f}'\n",
    "                         .format(epoch_id, batch_id + 1, len(bert_dataloader),\n",
    "                                 step_loss / log_interval,\n",
    "                                 trainer.learning_rate, metric.get()[1]))\n",
    "            step_loss = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the BERT model. Various models trained on Natural Language Inference (NLI) https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/nli-models.md and \n",
    "# Semantic Textual Similarity are available https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/sts-models.md\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence_df = pd.read_csv('train_bert.csv',engine='python')\n",
    "sentence_df = pd.read_csv('train_universal_sentence.csv',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = sentence_df.RefAnswer.astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A barcode is a series of light and dark bars of differing widths ', 'With a code number printed underneath', 'Made up of country of origin code, manufacturer code, the product code, a check digit.', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan']\n"
     ]
    }
   ],
   "source": [
    "print(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample BERT embedding vector - length 768\n",
      "Sample BERT embedding vector - note includes negative values [ 9.15223420e-01  4.33433205e-01  3.87063809e-03  3.62613618e-01\n",
      "  5.39999843e-01  5.09764671e-01  5.00931263e-01  2.77469307e-02\n",
      " -3.76719952e-01 -6.67793572e-01 -7.19707906e-01 -2.09060386e-01\n",
      " -2.01652005e-01  6.28048956e-01  7.39025474e-01  7.78510869e-01\n",
      "  1.95034966e-01 -4.08038944e-02  2.60271579e-02 -2.20886350e-01\n",
      " -8.19787160e-02  8.56281281e-01 -6.85880005e-01 -1.09536421e+00\n",
      "  2.08608598e-01  2.14172397e-02  2.01437071e-01  5.61132729e-02\n",
      " -7.94450462e-01 -2.12467849e-01  7.94746757e-01  7.40739763e-01\n",
      " -6.82536466e-03  6.25642715e-03  7.45293617e-01 -6.95767403e-02\n",
      "  7.14476183e-02 -4.05434728e-01  1.03005624e+00  2.79981554e-01\n",
      "  1.10992229e+00 -5.36680877e-01  6.19239569e-01 -5.54652512e-01\n",
      " -1.88014597e-01 -6.52552247e-01  3.76414061e-01 -4.20311511e-01\n",
      " -8.40249002e-01 -1.80035219e-01 -3.29662055e-01  1.65305451e-01\n",
      "  6.87114000e-01  1.05758023e+00 -3.56784016e-01  4.19278555e-02\n",
      "  1.02044427e+00 -3.71287353e-02  1.01193988e+00  1.69189766e-01\n",
      "  4.85913098e-01 -5.97837090e-01 -6.62155509e-01  3.28710556e-01\n",
      " -7.42024839e-01  6.68608606e-01  1.94317952e-01 -3.97207826e-01\n",
      " -1.40482008e-01  6.47036582e-02  9.76022482e-01 -1.37208685e-01\n",
      " -5.37546039e-01 -5.28278112e-01 -6.38114691e-01 -5.42269230e-01\n",
      " -3.37973959e-03  6.93756163e-01 -3.73417377e-01  1.78269193e-01\n",
      " -2.45029572e-02  4.02144045e-01  9.30421770e-01  2.52314210e-01\n",
      " -4.80846018e-01 -4.20951128e-01  5.70999742e-01  8.87692511e-01\n",
      " -6.50717378e-01  5.86367249e-02  4.54552770e-01  5.80688238e-01\n",
      "  1.10991812e+00  2.08504885e-01 -2.76538849e-01 -5.68455577e-01\n",
      "  2.93182760e-01 -2.05264181e-01  2.38502949e-01  1.84690773e-01\n",
      " -6.53110862e-01 -1.28537908e-01  3.39962035e-01  9.49036658e-01\n",
      " -3.76105458e-01  1.10434406e-01 -1.03336066e-01  5.82153857e-01\n",
      " -2.39302725e-01  9.95786428e-01 -7.58893311e-01  5.82228974e-02\n",
      "  7.53387749e-01 -8.15243244e-01 -6.88163280e-01 -5.96905172e-01\n",
      " -8.70155454e-01 -2.05952525e-02 -3.65152389e-01  1.13143098e+00\n",
      "  2.14244321e-01  8.13370883e-01  1.14420064e-01  5.36229670e-01\n",
      "  1.60426438e+00 -8.49595487e-01  8.66067767e-01  1.69695333e-01\n",
      " -3.85458231e-01  6.53577864e-01  5.37706912e-01  5.25489748e-01\n",
      " -1.54029811e-02 -2.92839378e-01 -1.17952156e+00 -6.86801895e-02\n",
      "  1.87770396e-01 -2.57797390e-01 -7.55351901e-01 -9.96210098e-01\n",
      " -4.49463010e-01 -1.38495475e-01 -1.36152163e-01 -3.33279848e-01\n",
      " -7.31045783e-01 -5.62157869e-01  6.68905973e-01 -1.22947231e-01\n",
      " -1.05279064e+00  1.79914489e-01 -1.38296112e-01 -1.78594604e-01\n",
      " -4.10858065e-01 -1.14147905e-02 -5.34148335e-01 -5.06118655e-01\n",
      " -3.57692808e-01  5.69588184e-01 -3.70070189e-01  1.42598003e-01\n",
      " -5.61330080e-01  1.03201962e+00 -1.45125940e-01 -4.00634259e-01\n",
      "  6.82328701e-01 -6.97929645e-03 -5.03865957e-01 -1.51673168e-01\n",
      " -4.27752703e-01  1.06726401e-01  1.07695103e+00 -7.25570440e-01\n",
      " -3.46872181e-01 -1.42757967e-01 -8.74064624e-01 -7.08080456e-02\n",
      " -1.02408983e-01  1.07952595e+00  6.69234037e-01 -8.50422561e-01\n",
      "  1.45734474e-01  5.37807159e-02  5.36537170e-01  2.03874871e-01\n",
      " -3.93207788e-01 -6.42699242e-01 -2.35490516e-01 -6.93984210e-01\n",
      "  6.06825113e-01 -4.51326907e-01 -1.24175884e-01 -8.82872701e-01\n",
      " -5.75165272e-01 -7.85707176e-01 -2.38608867e-01 -3.95629369e-02\n",
      " -6.37681663e-01  7.50514865e-02 -2.68174350e-01  5.49734533e-01\n",
      "  5.09039462e-01 -2.11830288e-01  3.23595524e-01  3.66118312e-01\n",
      " -5.48432052e-01  5.57425380e-01  4.66959357e-01  6.17202103e-01\n",
      " -1.34777725e+00 -2.92526364e-01 -2.19956025e-01  3.30954909e-01\n",
      " -4.01298732e-01  2.43392028e-02  4.84675854e-01  4.91718918e-01\n",
      "  5.93221188e-01 -4.43617284e-01  7.04551101e-01  8.73918056e-01\n",
      "  5.08524299e-01 -8.63993526e-01  4.59128588e-01  5.24009228e-01\n",
      " -3.25274557e-01  1.27231038e+00  5.15283108e-01  7.02022851e-01\n",
      "  9.81718183e-01  7.55155861e-01  7.26942837e-01  3.87434423e-01\n",
      "  7.16972956e-03  7.06471056e-02 -3.02833974e-01 -4.17044699e-01\n",
      "  7.40821660e-01 -5.56040779e-02  1.06740880e+00 -2.73871541e-01\n",
      "  1.60098433e-01  2.01231360e-01  1.15949821e+00  7.75347531e-01\n",
      " -1.30718839e+00 -9.09249365e-01 -3.57619405e-01 -4.47996646e-01\n",
      " -5.96037619e-02  3.71559471e-01  2.62526572e-01 -4.02791589e-01\n",
      "  6.70648098e-01 -2.96975616e-02  1.15141582e+00  7.47448877e-02\n",
      "  8.64498410e-03 -8.41316104e-01  4.36429054e-01 -1.36611462e+00\n",
      " -7.16077447e-01 -3.38448673e-01  5.08245707e-01 -2.50814795e-01\n",
      " -8.48429143e-01  2.59328961e-01 -1.10256386e+00  1.16653872e+00\n",
      " -5.51180691e-02  5.77920973e-01  5.16459227e-01  5.72836697e-01\n",
      " -1.06013978e+00 -3.80510360e-01  2.41459966e-01 -3.37687496e-04\n",
      "  2.17855287e+00 -2.40176082e-01  5.58348261e-02 -2.28487998e-01\n",
      " -1.02752495e+00  6.79467469e-02 -9.67845917e-01  3.60373169e-01\n",
      " -3.78489122e-02  9.20048878e-02  7.02843726e-01 -1.06274235e+00\n",
      " -8.61415192e-02  4.24653351e-01 -1.08605862e-01  1.38964987e+00\n",
      " -6.00404203e-01 -1.11555874e+00  1.42567735e-02 -1.82254553e-01\n",
      " -1.81265160e-01 -7.54753947e-02 -2.14198127e-01  6.42283782e-02\n",
      " -4.06408280e-01 -4.31065738e-01 -2.97234058e-01  9.65905011e-01\n",
      " -2.51504093e-01 -2.95389861e-01 -1.80508301e-01  1.18893564e+00\n",
      " -1.40586770e+00  1.59872144e-01 -3.82521510e-01  6.10311985e-01\n",
      " -7.99758852e-01  3.78272384e-02 -7.48417914e-01  3.00931394e-01\n",
      " -2.28931233e-01 -1.10321987e+00 -1.04457736e-01 -1.37272263e+00\n",
      " -3.48674893e-01  6.08058453e-01  6.33788884e-01 -1.93790682e-02\n",
      "  1.36469439e-01  3.21654856e-01  1.92498729e-01  7.25465417e-01\n",
      " -1.11747757e-01 -1.99989036e-01  8.64411354e-01 -1.35018110e+00\n",
      " -3.09761345e-01  5.72181702e-01  2.83727348e-01  5.21665156e-01\n",
      " -5.64821482e-01 -5.90752125e-01 -9.29402374e-03 -2.19051585e-01\n",
      " -5.55865467e-01 -5.73032439e-01  3.49280924e-01 -1.24570228e-01\n",
      "  7.70342946e-01 -1.02275407e+00 -1.03543371e-01 -3.65026325e-01\n",
      "  4.32459593e-01  1.00808394e+00 -4.44796145e-01  5.54796994e-01\n",
      " -3.14921498e-01 -9.41275060e-02 -4.09170389e-01 -6.51493907e-01\n",
      " -2.10915953e-02  7.90986940e-02 -4.21517074e-01  1.19752419e+00\n",
      " -7.91697383e-01  7.35443175e-01 -9.53054950e-02 -4.27772909e-01\n",
      "  2.08579004e-01 -4.08549160e-01  3.51704597e-01 -4.26399708e-01\n",
      "  1.23889005e+00 -1.39227167e-01 -4.25383806e-01 -6.20670021e-01\n",
      "  3.79273415e-01 -7.57386982e-01 -7.65266418e-01  4.16833386e-02\n",
      "  4.89528775e-01 -3.22993755e-01  5.27971424e-02 -1.01372731e+00\n",
      "  1.17175198e+00 -3.16566616e-01  1.75633222e-01  1.74136624e-01\n",
      "  9.83092129e-01 -2.09204003e-01  6.38429880e-01 -5.98221362e-01\n",
      " -7.70986438e-01 -4.34943408e-01  9.88102436e-01  1.36964649e-01\n",
      " -3.23952913e-01 -8.19304943e-01 -1.03979504e+00 -4.07515794e-01\n",
      " -2.31476173e-01  7.86566883e-02  2.58288264e-01 -1.16541617e-01\n",
      " -9.66632843e-01 -6.50732517e-01  9.75817978e-01  1.56594598e+00\n",
      "  7.37912133e-02  1.32714167e-01  1.83597863e-01  3.87198895e-01\n",
      "  2.19832286e-01 -1.03165627e+00 -4.12260890e-01  3.20119202e-01\n",
      "  2.71550000e-01  8.90767813e-01 -7.83281565e-01 -6.77737594e-01\n",
      " -6.24741009e-03 -7.67981589e-01 -2.76842475e-01  4.93052661e-01\n",
      " -5.55914223e-01 -1.98704407e-01  6.10724509e-01 -5.83865285e-01\n",
      " -6.42512321e-01  6.61534309e-01 -2.64064014e-01 -3.66951555e-01\n",
      " -1.62499368e-01  8.28805447e-01  2.99381703e-01 -3.78962576e-01\n",
      " -1.62311399e+00 -1.05277918e-01 -3.57383490e-01  5.03870323e-02\n",
      " -5.95086813e-02 -1.59613222e-01  2.58972675e-01  2.58022189e-01\n",
      "  3.17108482e-01 -5.75102270e-01  4.08090949e-01  6.72094405e-01\n",
      " -2.51974957e-03 -7.51513615e-02 -1.07059158e-01 -4.36692178e-01\n",
      "  4.49843585e-01 -5.46840966e-01  4.18161303e-01 -1.24234393e-01\n",
      " -1.30614087e-01  3.20401073e-01  4.86273199e-01 -7.99249828e-01\n",
      " -2.76672125e-01  6.82707667e-01  1.07320391e-01 -1.28977406e+00\n",
      "  2.43732035e-01 -9.89545137e-02  5.96677549e-02  2.05172017e-01\n",
      "  7.97878861e-01  8.70876551e-01 -5.12881815e-01 -4.16746825e-01\n",
      "  4.65453953e-01  2.43265033e-01  9.85849574e-02 -2.30932638e-01\n",
      " -7.97336280e-01  7.59667009e-02  4.50881571e-01  9.97212708e-01\n",
      " -8.62464964e-01  4.41198319e-01 -5.71380198e-01  1.97978303e-01\n",
      "  4.46852237e-01  4.61291939e-01 -7.80548453e-01  9.10747766e-01\n",
      " -1.27494943e+00  5.52620180e-02 -4.74732727e-01 -1.85349479e-01\n",
      "  3.72040629e-01 -4.99785930e-01 -4.40669209e-01 -3.11481357e-01\n",
      " -6.60166621e-01 -8.78042996e-01 -8.82597268e-01  7.00089097e-01\n",
      " -8.57983053e-01 -9.63675320e-01  3.30663145e-01  1.83704093e-01\n",
      "  1.14689863e+00 -2.64880359e-01 -1.83989748e-01 -1.19390798e+00\n",
      " -2.38770068e-01 -7.49541968e-02  6.40834272e-01 -1.20760036e+00\n",
      "  2.54741102e-01  3.38065594e-01 -4.92605478e-01 -1.69245243e-01\n",
      " -6.60633385e-01 -5.52379727e-01  1.76804915e-01 -8.42505619e-02\n",
      " -6.99727178e-01  2.59604275e-01 -3.57270092e-01 -1.17674541e+00\n",
      " -2.73533851e-01  1.56120136e-01  2.05847710e-01 -6.11708649e-02\n",
      " -1.37527868e-01  3.39401215e-01  1.29582834e+00  6.62880898e-01\n",
      "  9.17034507e-01 -8.58591795e-01  3.94584417e-01  8.11073899e-01\n",
      " -3.54392268e-02  1.10415682e-01  2.82556772e-01  8.00419673e-02\n",
      "  3.29334706e-01  6.35590911e-01  5.08068442e-01 -2.93715656e-01\n",
      "  1.54765146e-02  8.42226923e-01 -4.43117440e-01 -2.72611585e-02\n",
      " -1.11717069e+00 -2.03628927e-01  5.85029423e-01 -7.73579776e-02\n",
      "  8.25152695e-01  5.00537045e-02 -1.43340811e-01  1.45238042e-01\n",
      "  1.66032702e-01  3.91212016e-01 -9.90589261e-02  3.75549309e-02\n",
      " -1.25517893e+00  1.96186841e-01 -9.27129805e-01 -6.02965176e-01\n",
      "  4.69661921e-01  1.59765840e-01 -1.25081778e-01  7.32277393e-01\n",
      " -5.79964697e-01 -1.24614012e+00  3.75340581e-01  4.21773195e-01\n",
      " -3.12075853e-01 -1.21600580e+00  2.43946806e-01 -1.06063974e+00\n",
      "  1.62654921e-01  2.80695289e-01  3.58605832e-01 -1.23823121e-01\n",
      "  8.89787972e-02 -7.08014727e-01 -1.73813790e-01  5.37209027e-02\n",
      "  1.23256981e+00  4.13496643e-01  4.68663387e-02  5.89259081e-02\n",
      "  1.64708197e-01 -3.68352115e-01 -1.87011614e-01 -1.04610729e+00\n",
      " -1.87875018e-01 -3.57291430e-01  3.58728588e-01 -2.85824805e-01\n",
      "  1.36808485e-01 -2.50871211e-01 -1.86421275e-01 -4.77707475e-01\n",
      "  1.33881360e-01  1.22738950e-01 -5.34039028e-02  5.20296156e-01\n",
      "  4.26798351e-02  8.47332403e-02 -7.68523932e-01  2.08163068e-01\n",
      "  1.02201000e-01 -1.83667988e-01  2.54443884e-01 -8.17562580e-01\n",
      " -1.41426727e-01 -3.19430739e-01  1.63691700e-01 -8.21688235e-01\n",
      "  6.14552259e-01  1.28878534e-01 -1.82484806e-01 -7.19330728e-01\n",
      "  3.85496676e-01  9.80912685e-01  9.40466285e-01  6.21750593e-01\n",
      " -4.95802499e-02 -9.76247907e-01  1.05679941e+00 -1.83548748e-01\n",
      "  1.17855430e+00 -9.01109695e-01  8.90909195e-01 -6.53745830e-01\n",
      "  6.86123371e-01  9.86857474e-01  1.25015354e+00 -1.64236985e-02\n",
      " -6.85415924e-01 -7.37817362e-02  3.40680420e-01  7.55719244e-01\n",
      " -1.27549946e-01  1.88575447e-01  5.99685371e-01 -5.17812729e-01\n",
      " -4.86539513e-01 -1.49338937e+00 -5.12823880e-01  2.82775849e-01\n",
      " -5.62198600e-03  6.83101773e-01 -1.65244892e-01  1.76538587e-01\n",
      "  1.17561877e+00  4.26446766e-01 -4.39025581e-01 -4.48253423e-01\n",
      "  7.09590733e-01 -1.55722388e-04  2.89680868e-01 -8.07932913e-01\n",
      " -6.96575999e-01  3.37523878e-01 -2.83770207e-02  2.77776092e-01\n",
      "  6.88322186e-01  9.54965316e-03  3.37160796e-01  1.12546466e-01\n",
      "  6.82950795e-01  1.30730271e-01 -6.11707807e-01 -7.90012896e-01\n",
      "  5.65989733e-01  6.01294823e-02 -5.78345776e-01 -5.06389022e-01\n",
      " -7.01823235e-01 -9.15261209e-01  5.82535751e-03 -1.73568666e-01\n",
      "  7.73361266e-01 -9.81637716e-01 -4.62668777e-01 -1.24388528e+00\n",
      " -1.86952308e-01  3.69516820e-01 -9.96950865e-02 -1.94471374e-01\n",
      "  1.13817060e+00 -1.18829206e-01  8.99960697e-02  5.31573653e-01\n",
      "  6.98364913e-01  3.69827449e-02  6.16212070e-01 -7.73581624e-01\n",
      " -4.19582985e-02 -8.01826656e-01 -8.58738124e-02  9.37783659e-01\n",
      " -7.17475295e-01  3.08237791e-01 -3.23370069e-01 -4.66865569e-01\n",
      "  3.69083762e-01 -5.59253871e-01 -1.04880416e+00 -1.71516776e-01\n",
      " -1.22045293e-01  1.10256064e+00  3.09384167e-01 -6.40042782e-01\n",
      "  8.91245082e-02  3.64870667e-01 -7.65486211e-02  1.78809047e-01\n",
      " -4.36344832e-01  5.70459723e-01 -1.36471236e+00  1.20661283e+00\n",
      " -3.09849977e-01 -1.09699741e-01  4.20080423e-01 -1.03270853e+00\n",
      " -4.26427424e-01 -2.32411698e-01 -2.50312060e-01 -6.67495430e-01\n",
      "  3.02366495e-01 -4.29202914e-01  3.40562582e-01  5.39094992e-02\n",
      " -2.07505912e-01 -6.42902255e-01 -7.30930805e-01 -7.46052623e-01\n",
      " -3.52281108e-02  4.55795437e-01  5.91784716e-01  1.95129752e-01\n",
      "  8.86862278e-01  1.85606122e-01 -5.26028693e-01  2.62079060e-01\n",
      " -5.18115699e-01  7.22958326e-01 -1.10210605e-01 -7.89902091e-01\n",
      " -3.43186893e-02  3.53817225e-01 -3.87470305e-01 -1.10924184e-01\n",
      " -9.47777331e-01 -3.81110787e-01  6.06450200e-01 -3.56919318e-01\n",
      "  7.12535441e-01 -3.51836272e-02 -1.62912846e-01  3.64524186e-01\n",
      " -3.70609462e-01 -2.51667082e-01  3.34055454e-01 -2.11538672e-01\n",
      " -1.98861495e-01  9.31062698e-01  2.08105624e-01 -3.88036132e-01\n",
      " -4.92400602e-02  9.66241881e-02 -4.72941339e-01  2.14223683e-01]\n"
     ]
    }
   ],
   "source": [
    "# sentences = ['A barcode is a series of light and dark bars of differing widths', \n",
    "#              'With a code number printed underneath',\n",
    "#              'Made up of country of origin code, manufacturer code, the product code, a check digit.']\n",
    "\n",
    "# Each sentence is encoded as a 1-D vector with 78 columns\n",
    "sentence_embeddings = model.encode(sentence_list)\n",
    "\n",
    "print('Sample BERT embedding vector - length', len(sentence_embeddings[0]))\n",
    "\n",
    "print('Sample BERT embedding vector - note includes negative values', sentence_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_embeddings = model.encode(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(query_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#queries = sentence_df.StudentAnswer.astype(str).tolist()\n",
    "#query_embeddings = model.encode(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_universal_sentence.csv',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = test_df.StudentAnswer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#queries = ['Barcode is a unique series of parallel lines printed on a product. It is used to register check out price and stock management.', 'A barcode is a way to encode information visually that a machine can read. The combination of black and white bars (elements) represents a code for product identification.', 'A barcode is a series of light and dark bars of differing thickness.']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embeddings = model.encode(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode consists of light and dark bars of different widths, with a code number printed below the bars.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.9105)')\n",
      "0.9105138121526059\n",
      "[0.9105138121526059]\n",
      "('With a code number printed underneath', '(Score: 0.6889)')\n",
      "0.6888538652669248\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.5022)')\n",
      "0.5022032782791848\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "('nan', '(Score: 0.1636)')\n",
      "0.1635611849015829\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "('nan', '(Score: 0.1636)')\n",
      "0.1635611849015829\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "('nan', '(Score: 0.1636)')\n",
      "0.1635611849015829\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "('nan', '(Score: 0.1636)')\n",
      "0.1635611849015829\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "('nan', '(Score: 0.1636)')\n",
      "0.16356116075015392\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "('nan', '(Score: 0.1636)')\n",
      "0.16356116075015392\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "('nan', '(Score: 0.1636)')\n",
      "0.16356116075015392\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Made up of country of origin code, manufacturer code, the product code, a\n",
      "check digit.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 1.0000)')\n",
      "0.9999999999999643\n",
      "[0.9999999999999643]\n",
      "('With a code number printed underneath', '(Score: 0.7246)')\n",
      "0.7245870634907947\n",
      "[0.9999999999999643, 0.7245870634907947]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.4185)')\n",
      "0.41845998244045957\n",
      "[0.9999999999999643, 0.7245870634907947]\n",
      "('nan', '(Score: 0.3207)')\n",
      "0.3207128266851542\n",
      "[0.9999999999999643, 0.7245870634907947]\n",
      "('nan', '(Score: 0.3207)')\n",
      "0.3207128266851542\n",
      "[0.9999999999999643, 0.7245870634907947]\n",
      "('nan', '(Score: 0.3207)')\n",
      "0.3207128266851542\n",
      "[0.9999999999999643, 0.7245870634907947]\n",
      "('nan', '(Score: 0.3207)')\n",
      "0.3207128266851542\n",
      "[0.9999999999999643, 0.7245870634907947]\n",
      "('nan', '(Score: 0.3207)')\n",
      "0.32071276332643395\n",
      "[0.9999999999999643, 0.7245870634907947]\n",
      "('nan', '(Score: 0.3207)')\n",
      "0.32071276332643395\n",
      "[0.9999999999999643, 0.7245870634907947]\n",
      "('nan', '(Score: 0.3207)')\n",
      "0.32071276332643395\n",
      "[0.9999999999999643, 0.7245870634907947]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode is a rectangular strip comprising of light and deep colors with a code number printed used for product identification and selling.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('With a code number printed underneath', '(Score: 0.6249)')\n",
      "0.6248959938845874\n",
      "[0.6248959938845874]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.6181)')\n",
      "0.6180668479285772\n",
      "[0.6248959938845874, 0.6180668479285772]\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.6001)')\n",
      "0.6000971778204273\n",
      "[0.6248959938845874, 0.6180668479285772, 0.6000971778204273]\n",
      "('nan', '(Score: 0.1475)')\n",
      "0.14754864738945583\n",
      "[0.6248959938845874, 0.6180668479285772, 0.6000971778204273]\n",
      "('nan', '(Score: 0.1475)')\n",
      "0.14754864738945583\n",
      "[0.6248959938845874, 0.6180668479285772, 0.6000971778204273]\n",
      "('nan', '(Score: 0.1475)')\n",
      "0.14754864738945583\n",
      "[0.6248959938845874, 0.6180668479285772, 0.6000971778204273]\n",
      "('nan', '(Score: 0.1475)')\n",
      "0.14754864738945583\n",
      "[0.6248959938845874, 0.6180668479285772, 0.6000971778204273]\n",
      "('nan', '(Score: 0.1475)')\n",
      "0.14754857512857134\n",
      "[0.6248959938845874, 0.6180668479285772, 0.6000971778204273]\n",
      "('nan', '(Score: 0.1475)')\n",
      "0.14754857512857134\n",
      "[0.6248959938845874, 0.6180668479285772, 0.6000971778204273]\n",
      "('nan', '(Score: 0.1475)')\n",
      "0.14754857512857134\n",
      "[0.6248959938845874, 0.6180668479285772, 0.6000971778204273]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode is a bar with product code printed. It is attached to every product at retail shops.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.5448)')\n",
      "0.5447870601579763\n",
      "[]\n",
      "('With a code number printed underneath', '(Score: 0.3688)')\n",
      "0.36878787095313925\n",
      "[]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.2267)')\n",
      "0.2266502881835969\n",
      "[]\n",
      "('nan', '(Score: 0.0551)')\n",
      "0.05505207332558382\n",
      "[]\n",
      "('nan', '(Score: 0.0551)')\n",
      "0.05505207332558382\n",
      "[]\n",
      "('nan', '(Score: 0.0551)')\n",
      "0.05505207332558382\n",
      "[]\n",
      "('nan', '(Score: 0.0551)')\n",
      "0.05505207332558382\n",
      "[]\n",
      "('nan', '(Score: 0.0551)')\n",
      "0.05505206125639173\n",
      "[]\n",
      "('nan', '(Score: 0.0551)')\n",
      "0.05505206125639173\n",
      "[]\n",
      "('nan', '(Score: 0.0551)')\n",
      "0.05505206125639173\n",
      "[]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: It is a machine readable numbers arranged in a sequence comprising of parallel lines of different widths on a package. This is used for electronic scanning of goods at checkout to register price.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.6764)')\n",
      "0.6763861235895455\n",
      "[0.6763861235895455]\n",
      "('With a code number printed underneath', '(Score: 0.4916)')\n",
      "0.4915808046437993\n",
      "[0.6763861235895455]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.3537)')\n",
      "0.35369312541086373\n",
      "[0.6763861235895455]\n",
      "('nan', '(Score: 0.1007)')\n",
      "0.10068778979094595\n",
      "[0.6763861235895455]\n",
      "('nan', '(Score: 0.1007)')\n",
      "0.10068778979094595\n",
      "[0.6763861235895455]\n",
      "('nan', '(Score: 0.1007)')\n",
      "0.10068778979094595\n",
      "[0.6763861235895455]\n",
      "('nan', '(Score: 0.1007)')\n",
      "0.10068778979094595\n",
      "[0.6763861235895455]\n",
      "('nan', '(Score: 0.1007)')\n",
      "0.10068774744311881\n",
      "[0.6763861235895455]\n",
      "('nan', '(Score: 0.1007)')\n",
      "0.10068774744311881\n",
      "[0.6763861235895455]\n",
      "('nan', '(Score: 0.1007)')\n",
      "0.10068774744311881\n",
      "[0.6763861235895455]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Barcode is a unique series of parallel lines printed on a product. It is used to register check out price and stock management.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.6631)')\n",
      "0.6630513560739365\n",
      "[0.6630513560739365]\n",
      "('With a code number printed underneath', '(Score: 0.4536)')\n",
      "0.4536048642268803\n",
      "[0.6630513560739365]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.4388)')\n",
      "0.4387646949388262\n",
      "[0.6630513560739365]\n",
      "('nan', '(Score: 0.0871)')\n",
      "0.08707548299765944\n",
      "[0.6630513560739365]\n",
      "('nan', '(Score: 0.0871)')\n",
      "0.08707548299765944\n",
      "[0.6630513560739365]\n",
      "('nan', '(Score: 0.0871)')\n",
      "0.08707548299765944\n",
      "[0.6630513560739365]\n",
      "('nan', '(Score: 0.0871)')\n",
      "0.08707548299765944\n",
      "[0.6630513560739365]\n",
      "('nan', '(Score: 0.0871)')\n",
      "0.08707545245170689\n",
      "[0.6630513560739365]\n",
      "('nan', '(Score: 0.0871)')\n",
      "0.08707545245170689\n",
      "[0.6630513560739365]\n",
      "('nan', '(Score: 0.0871)')\n",
      "0.08707545245170689\n",
      "[0.6630513560739365]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Barcode uses a phone's camera to turn itself into a barcode scanner to find the best deal.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.5178)')\n",
      "0.5177805254364686\n",
      "[]\n",
      "('With a code number printed underneath', '(Score: 0.3991)')\n",
      "0.3990929513344006\n",
      "[]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.2968)')\n",
      "0.2968435199288335\n",
      "[]\n",
      "('nan', '(Score: -0.0077)')\n",
      "-0.007726674008938339\n",
      "[]\n",
      "('nan', '(Score: -0.0077)')\n",
      "-0.007726674008938339\n",
      "[]\n",
      "('nan', '(Score: -0.0077)')\n",
      "-0.007726674008938339\n",
      "[]\n",
      "('nan', '(Score: -0.0077)')\n",
      "-0.007726674008938339\n",
      "[]\n",
      "('nan', '(Score: -0.0077)')\n",
      "-0.007726741802825066\n",
      "[]\n",
      "('nan', '(Score: -0.0077)')\n",
      "-0.007726741802825066\n",
      "[]\n",
      "('nan', '(Score: -0.0077)')\n",
      "-0.007726741802825066\n",
      "[]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode is a small image of lines and spaces attached to retail store items. It is used to identify products, location and manufacturer.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.5932)')\n",
      "0.5932123963296407\n",
      "[]\n",
      "('With a code number printed underneath', '(Score: 0.4496)')\n",
      "0.44960498706779806\n",
      "[]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.4096)')\n",
      "0.4096006276678521\n",
      "[]\n",
      "('nan', '(Score: 0.1788)')\n",
      "0.1788158961339087\n",
      "[]\n",
      "('nan', '(Score: 0.1788)')\n",
      "0.1788158961339087\n",
      "[]\n",
      "('nan', '(Score: 0.1788)')\n",
      "0.1788158961339087\n",
      "[]\n",
      "('nan', '(Score: 0.1788)')\n",
      "0.1788158961339087\n",
      "[]\n",
      "('nan', '(Score: 0.1788)')\n",
      "0.17881589118255792\n",
      "[]\n",
      "('nan', '(Score: 0.1788)')\n",
      "0.17881589118255792\n",
      "[]\n",
      "('nan', '(Score: 0.1788)')\n",
      "0.17881589118255792\n",
      "[]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode consists of black vertical lines that can be seen at the right corner of the back of the product. It is used for product screening.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.5440)')\n",
      "0.5440332633400446\n",
      "[]\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.5259)')\n",
      "0.5259483281745896\n",
      "[]\n",
      "('With a code number printed underneath', '(Score: 0.4824)')\n",
      "0.48244275225367883\n",
      "[]\n",
      "('nan', '(Score: 0.0441)')\n",
      "0.04410916501394302\n",
      "[]\n",
      "('nan', '(Score: 0.0441)')\n",
      "0.04410916501394302\n",
      "[]\n",
      "('nan', '(Score: 0.0441)')\n",
      "0.04410916501394302\n",
      "[]\n",
      "('nan', '(Score: 0.0441)')\n",
      "0.04410916501394302\n",
      "[]\n",
      "('nan', '(Score: 0.0441)')\n",
      "0.044109145209684675\n",
      "[]\n",
      "('nan', '(Score: 0.0441)')\n",
      "0.044109145209684675\n",
      "[]\n",
      "('nan', '(Score: 0.0441)')\n",
      "0.044109145209684675\n",
      "[]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode is a code present on the back of the product which identifies the product.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.7319)')\n",
      "0.7318925076820422\n",
      "[0.7318925076820422]\n",
      "('With a code number printed underneath', '(Score: 0.6414)')\n",
      "0.641407722782624\n",
      "[0.7318925076820422, 0.641407722782624]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.4621)')\n",
      "0.4620809310943004\n",
      "[0.7318925076820422, 0.641407722782624]\n",
      "('nan', '(Score: 0.1297)')\n",
      "0.1296922335878793\n",
      "[0.7318925076820422, 0.641407722782624]\n",
      "('nan', '(Score: 0.1297)')\n",
      "0.1296922335878793\n",
      "[0.7318925076820422, 0.641407722782624]\n",
      "('nan', '(Score: 0.1297)')\n",
      "0.1296922335878793\n",
      "[0.7318925076820422, 0.641407722782624]\n",
      "('nan', '(Score: 0.1297)')\n",
      "0.1296922335878793\n",
      "[0.7318925076820422, 0.641407722782624]\n",
      "('nan', '(Score: 0.1297)')\n",
      "0.12969217674676836\n",
      "[0.7318925076820422, 0.641407722782624]\n",
      "('nan', '(Score: 0.1297)')\n",
      "0.12969217674676836\n",
      "[0.7318925076820422, 0.641407722782624]\n",
      "('nan', '(Score: 0.1297)')\n",
      "0.12969217674676836\n",
      "[0.7318925076820422, 0.641407722782624]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode is a way to encode information visually that a machine can read. The combination of black and white bars (elements) represents a code for product identification.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.6459)')\n",
      "0.6459333605048219\n",
      "[0.6459333605048219]\n",
      "('With a code number printed underneath', '(Score: 0.5479)')\n",
      "0.5479170556803951\n",
      "[0.6459333605048219]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.4611)')\n",
      "0.4610863490859476\n",
      "[0.6459333605048219]\n",
      "('nan', '(Score: -0.0107)')\n",
      "-0.010707934573070066\n",
      "[0.6459333605048219]\n",
      "('nan', '(Score: -0.0107)')\n",
      "-0.010707934573070066\n",
      "[0.6459333605048219]\n",
      "('nan', '(Score: -0.0107)')\n",
      "-0.010707934573070066\n",
      "[0.6459333605048219]\n",
      "('nan', '(Score: -0.0107)')\n",
      "-0.010707934573070066\n",
      "[0.6459333605048219]\n",
      "('nan', '(Score: -0.0107)')\n",
      "-0.010708002216158974\n",
      "[0.6459333605048219]\n",
      "('nan', '(Score: -0.0107)')\n",
      "-0.010708002216158974\n",
      "[0.6459333605048219]\n",
      "('nan', '(Score: -0.0107)')\n",
      "-0.010708002216158974\n",
      "[0.6459333605048219]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Barcodes are applied to products for quick identification electronically. It is a series of light and dark vertical bars representing a machine readable code number.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.6480)')\n",
      "0.6480035442614771\n",
      "[0.6480035442614771]\n",
      "('With a code number printed underneath', '(Score: 0.6247)')\n",
      "0.6246990235567064\n",
      "[0.6480035442614771, 0.6246990235567064]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.4496)')\n",
      "0.44963971324102325\n",
      "[0.6480035442614771, 0.6246990235567064]\n",
      "('nan', '(Score: 0.0668)')\n",
      "0.06675027068278416\n",
      "[0.6480035442614771, 0.6246990235567064]\n",
      "('nan', '(Score: 0.0668)')\n",
      "0.06675027068278416\n",
      "[0.6480035442614771, 0.6246990235567064]\n",
      "('nan', '(Score: 0.0668)')\n",
      "0.06675027068278416\n",
      "[0.6480035442614771, 0.6246990235567064]\n",
      "('nan', '(Score: 0.0668)')\n",
      "0.06675027068278416\n",
      "[0.6480035442614771, 0.6246990235567064]\n",
      "('nan', '(Score: 0.0668)')\n",
      "0.0667502089514388\n",
      "[0.6480035442614771, 0.6246990235567064]\n",
      "('nan', '(Score: 0.0668)')\n",
      "0.0667502089514388\n",
      "[0.6480035442614771, 0.6246990235567064]\n",
      "('nan', '(Score: 0.0668)')\n",
      "0.0667502089514388\n",
      "[0.6480035442614771, 0.6246990235567064]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode is a series of white and black bars of differing widths. It is pasted on the products in a retail store for easy information of any product.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.4945)')\n",
      "0.49446505283617714\n",
      "[]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.3858)')\n",
      "0.3858129771636323\n",
      "[]\n",
      "('With a code number printed underneath', '(Score: 0.3731)')\n",
      "0.3730705423734002\n",
      "[]\n",
      "('nan', '(Score: -0.0702)')\n",
      "-0.07016594702718604\n",
      "[]\n",
      "('nan', '(Score: -0.0702)')\n",
      "-0.07016594702718604\n",
      "[]\n",
      "('nan', '(Score: -0.0702)')\n",
      "-0.07016594702718604\n",
      "[]\n",
      "('nan', '(Score: -0.0702)')\n",
      "-0.07016594702718604\n",
      "[]\n",
      "('nan', '(Score: -0.0702)')\n",
      "-0.07016598956106779\n",
      "[]\n",
      "('nan', '(Score: -0.0702)')\n",
      "-0.07016598956106779\n",
      "[]\n",
      "('nan', '(Score: -0.0702)')\n",
      "-0.07016598956106779\n",
      "[]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode is represnted by a sequence of light and dark bars of different widths. Barcode is helpful in tagging the prices of products.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.6407)')\n",
      "0.6407335501506731\n",
      "[0.6407335501506731]\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.5419)')\n",
      "0.5419308174427157\n",
      "[0.6407335501506731]\n",
      "('With a code number printed underneath', '(Score: 0.4609)')\n",
      "0.4609182782119703\n",
      "[0.6407335501506731]\n",
      "('nan', '(Score: 0.0812)')\n",
      "0.08121561994260529\n",
      "[0.6407335501506731]\n",
      "('nan', '(Score: 0.0812)')\n",
      "0.08121561994260529\n",
      "[0.6407335501506731]\n",
      "('nan', '(Score: 0.0812)')\n",
      "0.08121561994260529\n",
      "[0.6407335501506731]\n",
      "('nan', '(Score: 0.0812)')\n",
      "0.08121561994260529\n",
      "[0.6407335501506731]\n",
      "('nan', '(Score: 0.0812)')\n",
      "0.08121555998829033\n",
      "[0.6407335501506731]\n",
      "('nan', '(Score: 0.0812)')\n",
      "0.08121555998829033\n",
      "[0.6407335501506731]\n",
      "('nan', '(Score: 0.0812)')\n",
      "0.08121555998829033\n",
      "[0.6407335501506731]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode is a series of light and dark bars of differing thickness.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.9861)')\n",
      "0.9860841177461741\n",
      "[0.9860841177461741]\n",
      "('With a code number printed underneath', '(Score: 0.5539)')\n",
      "0.5538882332335832\n",
      "[0.9860841177461741]\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.4279)')\n",
      "0.42792167932147596\n",
      "[0.9860841177461741]\n",
      "('nan', '(Score: 0.2834)')\n",
      "0.2833998805359854\n",
      "[0.9860841177461741]\n",
      "('nan', '(Score: 0.2834)')\n",
      "0.2833998805359854\n",
      "[0.9860841177461741]\n",
      "('nan', '(Score: 0.2834)')\n",
      "0.2833998805359854\n",
      "[0.9860841177461741]\n",
      "('nan', '(Score: 0.2834)')\n",
      "0.2833998805359854\n",
      "[0.9860841177461741]\n",
      "('nan', '(Score: 0.2834)')\n",
      "0.28339983885608877\n",
      "[0.9860841177461741]\n",
      "('nan', '(Score: 0.2834)')\n",
      "0.28339983885608877\n",
      "[0.9860841177461741]\n",
      "('nan', '(Score: 0.2834)')\n",
      "0.28339983885608877\n",
      "[0.9860841177461741]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Barcode is a kind of code with bars with a code number printed underneath.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('With a code number printed underneath', '(Score: 0.7524)')\n",
      "0.7523917381704237\n",
      "[0.7523917381704237]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.6629)')\n",
      "0.6629473568880582\n",
      "[0.7523917381704237, 0.6629473568880582]\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.6593)')\n",
      "0.659283979838504\n",
      "[0.7523917381704237, 0.6629473568880582, 0.659283979838504]\n",
      "('nan', '(Score: 0.1757)')\n",
      "0.17567835865688097\n",
      "[0.7523917381704237, 0.6629473568880582, 0.659283979838504]\n",
      "('nan', '(Score: 0.1757)')\n",
      "0.17567835865688097\n",
      "[0.7523917381704237, 0.6629473568880582, 0.659283979838504]\n",
      "('nan', '(Score: 0.1757)')\n",
      "0.17567835865688097\n",
      "[0.7523917381704237, 0.6629473568880582, 0.659283979838504]\n",
      "('nan', '(Score: 0.1757)')\n",
      "0.17567835865688097\n",
      "[0.7523917381704237, 0.6629473568880582, 0.659283979838504]\n",
      "('nan', '(Score: 0.1757)')\n",
      "0.17567833168301805\n",
      "[0.7523917381704237, 0.6629473568880582, 0.659283979838504]\n",
      "('nan', '(Score: 0.1757)')\n",
      "0.17567833168301805\n",
      "[0.7523917381704237, 0.6629473568880582, 0.659283979838504]\n",
      "('nan', '(Score: 0.1757)')\n",
      "0.17567833168301805\n",
      "[0.7523917381704237, 0.6629473568880582, 0.659283979838504]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Barcode is a series of bars with a code number printed at the bottom.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('With a code number printed underneath', '(Score: 0.7528)')\n",
      "0.752757650970474\n",
      "[0.752757650970474]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.6984)')\n",
      "0.6984035159527767\n",
      "[0.752757650970474, 0.6984035159527767]\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.6295)')\n",
      "0.6294517475513761\n",
      "[0.752757650970474, 0.6984035159527767, 0.6294517475513761]\n",
      "('nan', '(Score: 0.2236)')\n",
      "0.22363569490023127\n",
      "[0.752757650970474, 0.6984035159527767, 0.6294517475513761]\n",
      "('nan', '(Score: 0.2236)')\n",
      "0.22363569490023127\n",
      "[0.752757650970474, 0.6984035159527767, 0.6294517475513761]\n",
      "('nan', '(Score: 0.2236)')\n",
      "0.22363569490023127\n",
      "[0.752757650970474, 0.6984035159527767, 0.6294517475513761]\n",
      "('nan', '(Score: 0.2236)')\n",
      "0.22363569490023127\n",
      "[0.752757650970474, 0.6984035159527767, 0.6294517475513761]\n",
      "('nan', '(Score: 0.2236)')\n",
      "0.22363569490023127\n",
      "[0.752757650970474, 0.6984035159527767, 0.6294517475513761]\n",
      "('nan', '(Score: 0.2236)')\n",
      "0.22363569490023127\n",
      "[0.752757650970474, 0.6984035159527767, 0.6294517475513761]\n",
      "('nan', '(Score: 0.2236)')\n",
      "0.22363569490023127\n",
      "[0.752757650970474, 0.6984035159527767, 0.6294517475513761]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode is a code with bars and a number printed at the bottom.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('With a code number printed underneath', '(Score: 0.7693)')\n",
      "0.7693166260081648\n",
      "[0.7693166260081648]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.6910)')\n",
      "0.6910082229075879\n",
      "[0.7693166260081648, 0.6910082229075879]\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.6352)')\n",
      "0.635228079673809\n",
      "[0.7693166260081648, 0.6910082229075879, 0.635228079673809]\n",
      "('nan', '(Score: 0.2138)')\n",
      "0.21375221594463945\n",
      "[0.7693166260081648, 0.6910082229075879, 0.635228079673809]\n",
      "('nan', '(Score: 0.2138)')\n",
      "0.21375221594463945\n",
      "[0.7693166260081648, 0.6910082229075879, 0.635228079673809]\n",
      "('nan', '(Score: 0.2138)')\n",
      "0.21375221594463945\n",
      "[0.7693166260081648, 0.6910082229075879, 0.635228079673809]\n",
      "('nan', '(Score: 0.2138)')\n",
      "0.21375221594463945\n",
      "[0.7693166260081648, 0.6910082229075879, 0.635228079673809]\n",
      "('nan', '(Score: 0.2138)')\n",
      "0.21375221355073037\n",
      "[0.7693166260081648, 0.6910082229075879, 0.635228079673809]\n",
      "('nan', '(Score: 0.2138)')\n",
      "0.21375221355073037\n",
      "[0.7693166260081648, 0.6910082229075879, 0.635228079673809]\n",
      "('nan', '(Score: 0.2138)')\n",
      "0.21375221355073037\n",
      "[0.7693166260081648, 0.6910082229075879, 0.635228079673809]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Barcode is a code made up of country of origin code, manufacturer code, the product code, a check digit.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.9612)')\n",
      "0.9611920928030002\n",
      "[0.9611920928030002]\n",
      "('With a code number printed underneath', '(Score: 0.6919)')\n",
      "0.6918742644300816\n",
      "[0.9611920928030002, 0.6918742644300816]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.4562)')\n",
      "0.4561631545727962\n",
      "[0.9611920928030002, 0.6918742644300816]\n",
      "('nan', '(Score: 0.2357)')\n",
      "0.23567714069847445\n",
      "[0.9611920928030002, 0.6918742644300816]\n",
      "('nan', '(Score: 0.2357)')\n",
      "0.23567714069847445\n",
      "[0.9611920928030002, 0.6918742644300816]\n",
      "('nan', '(Score: 0.2357)')\n",
      "0.23567714069847445\n",
      "[0.9611920928030002, 0.6918742644300816]\n",
      "('nan', '(Score: 0.2357)')\n",
      "0.23567714069847445\n",
      "[0.9611920928030002, 0.6918742644300816]\n",
      "('nan', '(Score: 0.2357)')\n",
      "0.23567708492301087\n",
      "[0.9611920928030002, 0.6918742644300816]\n",
      "('nan', '(Score: 0.2357)')\n",
      "0.23567708492301087\n",
      "[0.9611920928030002, 0.6918742644300816]\n",
      "('nan', '(Score: 0.2357)')\n",
      "0.23567708492301087\n",
      "[0.9611920928030002, 0.6918742644300816]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode is composed of country code, manufacturer code, the product code, a check digit.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.9535)')\n",
      "0.953504427246708\n",
      "[0.953504427246708]\n",
      "('With a code number printed underneath', '(Score: 0.6980)')\n",
      "0.698029542467631\n",
      "[0.953504427246708, 0.698029542467631]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.4326)')\n",
      "0.43256425675596466\n",
      "[0.953504427246708, 0.698029542467631]\n",
      "('nan', '(Score: 0.2315)')\n",
      "0.23151060943589685\n",
      "[0.953504427246708, 0.698029542467631]\n",
      "('nan', '(Score: 0.2315)')\n",
      "0.23151060943589685\n",
      "[0.953504427246708, 0.698029542467631]\n",
      "('nan', '(Score: 0.2315)')\n",
      "0.23151060943589685\n",
      "[0.953504427246708, 0.698029542467631]\n",
      "('nan', '(Score: 0.2315)')\n",
      "0.23151060943589685\n",
      "[0.953504427246708, 0.698029542467631]\n",
      "('nan', '(Score: 0.2315)')\n",
      "0.23151056318392071\n",
      "[0.953504427246708, 0.698029542467631]\n",
      "('nan', '(Score: 0.2315)')\n",
      "0.23151056318392071\n",
      "[0.953504427246708, 0.698029542467631]\n",
      "('nan', '(Score: 0.2315)')\n",
      "0.23151056318392071\n",
      "[0.953504427246708, 0.698029542467631]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode is composed of manufacturer code, country of origin code, and the product code.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.9271)')\n",
      "0.9271267050131374\n",
      "[0.9271267050131374]\n",
      "('With a code number printed underneath', '(Score: 0.6205)')\n",
      "0.6205093478185951\n",
      "[0.9271267050131374, 0.6205093478185951]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.4002)')\n",
      "0.4001538348001552\n",
      "[0.9271267050131374, 0.6205093478185951]\n",
      "('nan', '(Score: 0.2375)')\n",
      "0.23747951530761435\n",
      "[0.9271267050131374, 0.6205093478185951]\n",
      "('nan', '(Score: 0.2375)')\n",
      "0.23747951530761435\n",
      "[0.9271267050131374, 0.6205093478185951]\n",
      "('nan', '(Score: 0.2375)')\n",
      "0.23747951530761435\n",
      "[0.9271267050131374, 0.6205093478185951]\n",
      "('nan', '(Score: 0.2375)')\n",
      "0.23747951530761435\n",
      "[0.9271267050131374, 0.6205093478185951]\n",
      "('nan', '(Score: 0.2375)')\n",
      "0.23747946582621404\n",
      "[0.9271267050131374, 0.6205093478185951]\n",
      "('nan', '(Score: 0.2375)')\n",
      "0.23747946582621404\n",
      "[0.9271267050131374, 0.6205093478185951]\n",
      "('nan', '(Score: 0.2375)')\n",
      "0.23747946582621404\n",
      "[0.9271267050131374, 0.6205093478185951]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode consists of light and dark bars of different widths, with a code number printed below the bars.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.9105)')\n",
      "0.9105138121526059\n",
      "[0.9105138121526059]\n",
      "('With a code number printed underneath', '(Score: 0.6889)')\n",
      "0.6888538652669248\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.5022)')\n",
      "0.5022032782791848\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "('nan', '(Score: 0.1636)')\n",
      "0.1635611849015829\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "('nan', '(Score: 0.1636)')\n",
      "0.1635611849015829\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "('nan', '(Score: 0.1636)')\n",
      "0.1635611849015829\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "('nan', '(Score: 0.1636)')\n",
      "0.1635611849015829\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "('nan', '(Score: 0.1636)')\n",
      "0.16356116075015392\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "('nan', '(Score: 0.1636)')\n",
      "0.16356116075015392\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "('nan', '(Score: 0.1636)')\n",
      "0.16356116075015392\n",
      "[0.9105138121526059, 0.6888538652669248]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode is a series of light and dark bars of differing widths with a code number printed underneath made up of country of origin code, manufacturer code, the product code, a check digit.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.8025)')\n",
      "0.8024919954121912\n",
      "[0.8024919954121912]\n",
      "('With a code number printed underneath', '(Score: 0.7253)')\n",
      "0.7253316259623752\n",
      "[0.8024919954121912, 0.7253316259623752]\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.7214)')\n",
      "0.7214018331782347\n",
      "[0.8024919954121912, 0.7253316259623752, 0.7214018331782347]\n",
      "('nan', '(Score: 0.1464)')\n",
      "0.14636256300592\n",
      "[0.8024919954121912, 0.7253316259623752, 0.7214018331782347]\n",
      "('nan', '(Score: 0.1464)')\n",
      "0.14636256300592\n",
      "[0.8024919954121912, 0.7253316259623752, 0.7214018331782347]\n",
      "('nan', '(Score: 0.1464)')\n",
      "0.14636256300592\n",
      "[0.8024919954121912, 0.7253316259623752, 0.7214018331782347]\n",
      "('nan', '(Score: 0.1464)')\n",
      "0.14636256300592\n",
      "[0.8024919954121912, 0.7253316259623752, 0.7214018331782347]\n",
      "('nan', '(Score: 0.1464)')\n",
      "0.14636252715629572\n",
      "[0.8024919954121912, 0.7253316259623752, 0.7214018331782347]\n",
      "('nan', '(Score: 0.1464)')\n",
      "0.14636252715629572\n",
      "[0.8024919954121912, 0.7253316259623752, 0.7214018331782347]\n",
      "('nan', '(Score: 0.1464)')\n",
      "0.14636252715629572\n",
      "[0.8024919954121912, 0.7253316259623752, 0.7214018331782347]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode is an electronic strip with black vertical line and some numbers printed below.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('With a code number printed underneath', '(Score: 0.7045)')\n",
      "0.7045042198094569\n",
      "[0.7045042198094569]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.6891)')\n",
      "0.6890721016947883\n",
      "[0.7045042198094569, 0.6890721016947883]\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.5540)')\n",
      "0.5540132190750032\n",
      "[0.7045042198094569, 0.6890721016947883]\n",
      "('nan', '(Score: 0.1555)')\n",
      "0.15550625291654185\n",
      "[0.7045042198094569, 0.6890721016947883]\n",
      "('nan', '(Score: 0.1555)')\n",
      "0.15550625291654185\n",
      "[0.7045042198094569, 0.6890721016947883]\n",
      "('nan', '(Score: 0.1555)')\n",
      "0.15550625291654185\n",
      "[0.7045042198094569, 0.6890721016947883]\n",
      "('nan', '(Score: 0.1555)')\n",
      "0.15550625291654185\n",
      "[0.7045042198094569, 0.6890721016947883]\n",
      "('nan', '(Score: 0.1555)')\n",
      "0.15550623910441674\n",
      "[0.7045042198094569, 0.6890721016947883]\n",
      "('nan', '(Score: 0.1555)')\n",
      "0.15550623910441674\n",
      "[0.7045042198094569, 0.6890721016947883]\n",
      "('nan', '(Score: 0.1555)')\n",
      "0.15550623910441674\n",
      "[0.7045042198094569, 0.6890721016947883]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A barcode is a series of bars. It has a lot of product information stored.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.6210)')\n",
      "0.6210005223262192\n",
      "[0.6210005223262192]\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.5562)')\n",
      "0.556159741398037\n",
      "[0.6210005223262192]\n",
      "('With a code number printed underneath', '(Score: 0.5253)')\n",
      "0.5252501966577071\n",
      "[0.6210005223262192]\n",
      "('nan', '(Score: 0.2375)')\n",
      "0.23746435129489718\n",
      "[0.6210005223262192]\n",
      "('nan', '(Score: 0.2375)')\n",
      "0.23746435129489718\n",
      "[0.6210005223262192]\n",
      "('nan', '(Score: 0.2375)')\n",
      "0.23746435129489718\n",
      "[0.6210005223262192]\n",
      "('nan', '(Score: 0.2375)')\n",
      "0.23746435129489718\n",
      "[0.6210005223262192]\n",
      "('nan', '(Score: 0.2375)')\n",
      "0.23746429696463223\n",
      "[0.6210005223262192]\n",
      "('nan', '(Score: 0.2375)')\n",
      "0.23746429696463223\n",
      "[0.6210005223262192]\n",
      "('nan', '(Score: 0.2375)')\n",
      "0.23746429696463223\n",
      "[0.6210005223262192]\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Barcodes are useful to have product information instead of physical stickers with price and other information mentoned on it.\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "('A barcode is a series of light and dark bars of differing widths', '(Score: 0.4819)')\n",
      "0.4818605991708218\n",
      "[]\n",
      "('Made up of country of origin code, manufacturer code, the product code, a check digit.', '(Score: 0.4592)')\n",
      "0.45920994146764693\n",
      "[]\n",
      "('With a code number printed underneath', '(Score: 0.4245)')\n",
      "0.4244634151712059\n",
      "[]\n",
      "('nan', '(Score: 0.1585)')\n",
      "0.15846741134578013\n",
      "[]\n",
      "('nan', '(Score: 0.1585)')\n",
      "0.15846741134578013\n",
      "[]\n",
      "('nan', '(Score: 0.1585)')\n",
      "0.15846741134578013\n",
      "[]\n",
      "('nan', '(Score: 0.1585)')\n",
      "0.15846741134578013\n",
      "[]\n",
      "('nan', '(Score: 0.1585)')\n",
      "0.15846736368808523\n",
      "[]\n",
      "('nan', '(Score: 0.1585)')\n",
      "0.15846736368808523\n",
      "[]\n",
      "('nan', '(Score: 0.1585)')\n",
      "0.15846736368808523\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Find the closest 3 sentences of the corpus for each query sentence based on cosine similarity\n",
    "closest_n = 10\n",
    "for query, query_embedding in zip(queries, query_embeddings):\n",
    "    distances = scipy.spatial.distance.cdist([query_embedding], sentence_embeddings, \"cosine\")[0]\n",
    "\n",
    "    results = zip(range(len(distances)), distances)\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 3 most similar sentences in corpus:\")\n",
    "    \n",
    "    results_list = []\n",
    "\n",
    "    for idx, distance in results[0:closest_n]:\n",
    "        score = sentence_list[idx].strip(), \"(Score: %.4f)\" % (1-distance)\n",
    "        print(score)\n",
    "        score_value = float((1-distance))\n",
    "        print(score_value)\n",
    "        if score_value[] >= 0.6:\n",
    "            results_list.append(score_value)\n",
    "        print(results_list)\n",
    "        #if float(score) > 0.6:\n",
    "            #results_list.add(0.6)\n",
    "            #print(results_list)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#print(results)\n",
    "\n",
    "# if results.astype(float) >= 0.6:\n",
    "#     print(\"OK\")\n",
    "# else:\n",
    "#     print(\"Negative\")\n",
    "    \n",
    "print(results_list) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for results in "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
